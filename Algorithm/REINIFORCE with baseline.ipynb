{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On the REINFORCE Algorithm in Sequence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulation\n",
    "- $\\omega^{s}$: Sampled sequence\n",
    "- $r(\\omega^{s})$: Reward given sampled sequence\n",
    "\n",
    "Loss function:\n",
    "\n",
    "$L(\\theta) = -\\mathop{\\mathbb{E}}_{\\omega^{s}\\sim p_{\\theta}(\\omega^{s})}[r(\\omega_{s})]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REIINFORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectation of policy gradient:\n",
    "$$\\nabla_{\\theta}\\mathop{\\mathbb{E}}_{\\omega^{s}\\sim p_{\\theta}(\\omega^{s})}[r(\\omega_{s})] =\\mathop{\\Sigma}_{\\omega^{s}}r(\\omega^{s})\\nabla_{\\theta}p_{\\theta}(\\omega^{s})\\\\\n",
    "=\\mathop{\\Sigma}_{\\omega^{s}}r(\\omega^{s})\\frac{\\nabla_{\\theta}p_{\\theta}(\\omega^{s})}{p_{\\theta}(\\omega^{s})}p_{\\theta}(\\omega^{s})\\\\\n",
    "=\\mathop{\\Sigma}_{\\omega^{s}}p_{\\theta}(\\omega^{s})\\cdot r(\\omega^{s})\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s})\\\\\n",
    "=\\mathop{\\mathbb{E}}_{\\omega^{s}\\sim p_{\\theta}(\\omega^{s})}r(\\omega^{s})\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s})\\\\\n",
    "\\approx \\frac{1}{N}\\mathop{\\Sigma}_{i=1}^{N}r(\\omega^{s_{i}})\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s_{i}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalize the policy gradient by adding baseline reward $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathop{\\mathbb{E}}_{\\omega^{s}\\sim p_{\\theta}(\\omega^{s})}[r(\\omega^{s})-b]\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Expectation of policy gradient does **NOT** change given $b$ is independent of $\\omega(s)$\n",
    "\n",
    "Proof:\n",
    "$$\\mathop{\\mathbb{E}}_{\\omega^{s}\\sim p_{\\theta}(\\omega^{s})}[r(\\omega^{s})-b]\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s}) = \\mathop{\\mathbb{E}}_{\\omega^{s}\\sim p_{\\theta}(\\omega^{s})}r(\\omega^{s})\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s})-\\mathop{\\mathbb{E}}_{\\omega^{s}\\sim p_{\\theta}(\\omega^{s})}b\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s})$$\n",
    "in which\n",
    "$$\\mathop{\\mathbb{E}}_{\\omega^{s}\\sim p_{\\theta}(\\omega^{s})}b\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s})=\\mathop{\\Sigma}_{\\omega^{s}}b\\frac{\\nabla_{\\theta}p_{\\theta}(\\omega^{s})}{p_{\\theta}(\\omega^{s})}\\cdot p_{\\theta}(\\omega^{s})=b\\mathop{\\Sigma}_{\\omega^{s}}\\nabla_{\\theta}p_{\\theta}(\\omega^{s})=b\\nabla_{\\theta}\\mathop{\\Sigma}_{\\omega^{s}}p_{\\theta}(\\omega^{s})=b\\nabla_{\\theta}1=0\n",
    "$$\n",
    "- Variance of gradient estimate got reduced\n",
    "\n",
    "With a total of $N$ trails, the expectation can be approximated with\n",
    "$$\\mathop{\\mathbb{E}}_{\\omega^{s}\\sim p_{\\theta}(\\omega^{s})}[r(\\omega^{s})-b]\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s}) \\approx \\frac{1}{N}\\mathop{\\Sigma}_{i=1}^{N}[r(\\omega^{s_{i}})-b]\\nabla_{\\theta}\\ln p_{\\theta}(\\omega^{s_{i}})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "[Self-critical Sequence Training for Image Captioning](https://arxiv.org/abs/1612.00563)\n",
    "\n",
    "[A Deep Reinforced Model for Abstractive Summarization](https://arxiv.org/abs/1705.04304)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit4aad875cf071498186715d87f6c3423a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
