{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextRank\n",
    "\n",
    "## TL;DR;\n",
    "\n",
    "The author extends the idea of PageRank:\n",
    "$$S(V_{i}) = (1-d) + d* \\sum_{V_{j}\\in In(V_{i})}\\frac{1}{\\vert Out(V_{j}) \\vert}WS(V_{j})$$\n",
    "by by introducing weights for updating score of each vertice:\n",
    "$$WS(V_{i}) = (1-d) + d* \\sum_{V_{j}\\in In(V_{i})}\\frac{w_{ji}}{\\sum_{v_{k}\\in Out(V_{j})}w_{jk}}WS(V_{j})$$,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of TextRank for Key Word Extraction\n",
    "For keyword extraction, simply extract words as vertices utilize word co-occurence as reference of edge weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example from [TextRank:Bringing Order into Texts](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds forcomponents of a minimal set of solutions and algorithms of construction ofminimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types systems and systems of mixed types.\"\n",
    "example_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply naive white space tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens = []\n",
    "    for word in map(lambda s: s.lower(), example_text.split(\" \")):\n",
    "        if word[-1] in \",.\":\n",
    "            tokens += word[:-1], word[-1]\n",
    "        else:\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.Series(tokenizer(example_text))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply syntactic filters & build graph. In this case we don't apply any filter at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_filter(token_a, token_b):\n",
    "    return True\n",
    "\n",
    "def construct_graph(tokens, synatic_filter, window_width=5):\n",
    "    vocab = tokens.unique()\n",
    "    mat = pd.DataFrame(index=vocab, columns=vocab)\n",
    "    for window_start in range(len(tokens) - window_width + 1):\n",
    "        window = tokens[window_start:window_start+window_width]\n",
    "        for token_a, token_b in itertools.combinations(window, 2):\n",
    "            if synatic_filter(token_a, token_b):\n",
    "                mat.loc[token_a][token_b] = 1.\n",
    "                mat.loc[token_b][token_a] = 1.\n",
    "    mat.fillna(0., inplace=True)\n",
    "    # Remove isolated vertices\n",
    "    deg = mat.values.sum(axis=1)\n",
    "    new_indices =mat.index[deg > 0]\n",
    "    mat = mat.loc[new_indices, new_indices]\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adj_mat = construct_graph(tokens, dummy_filter)\n",
    "adj_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate score of each vertice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_rank(adj_mat, d, threshold=1e-5, max_iter=100):\n",
    "    assert 0 < d < 1\n",
    "    vertices = adj_mat.index\n",
    "    cur_scores = pd.Series(index=vertices, dtype=float).fillna(1)\n",
    "    deg_o = adj_mat.sum(axis=1)\n",
    "    norm_adj_mat = adj_mat.div(deg_o, axis=1)\n",
    "    for _ in range(max_iter):\n",
    "        update = norm_adj_mat.mul(cur_scores, axis=1).sum(axis=1)\n",
    "        new_scores = (1 - d) + d * update\n",
    "        if np.linalg.norm(new_scores - cur_scores) < threshold:\n",
    "            return new_scores\n",
    "        cur_scores = new_scores\n",
    "    return cur_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text_rank(adj_mat,d=0.85, max_iter=100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
